{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa40ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "def get_video_comments(videos_df, access_token, fields=\"id,video_id,text,like_count,reply_count, create_time, parent_comment_id\", max_count=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Fetches comments for multiple videos and compiles them into a single DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - videos_df (pd.DataFrame): DataFrame with a column 'id' containing video IDs.\n",
    "    - access_token (str): Access token for TikTok's API.\n",
    "    - fields (str): Comma-separated string of fields to retrieve for each comment. Defaults to a basic set of fields.\n",
    "    - max_count (int): Maximum number of comments to retrieve per request (default is 100).\n",
    "    - verbose (bool): If True (default), prints detailed logs; if False, suppresses most print statements.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing all comments from the provided videos.\n",
    "    \"\"\"\n",
    "    endpoint = \"https://open.tiktokapis.com/v2/research/video/comment/list/\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\", \"Content-Type\": \"application/json\"}\n",
    "    all_comments_df = pd.DataFrame()\n",
    "    session = requests.Session()  # Use session for improved performance\n",
    "\n",
    "    for _, video in videos_df.iterrows():\n",
    "        video_id = video['id']\n",
    "        has_more = True\n",
    "        cursor = 0\n",
    "\n",
    "        while has_more and cursor < 1000:  # To respect the API's limit\n",
    "            body_params = {\"video_id\": video_id, \"max_count\": max_count, \"cursor\": cursor}\n",
    "            response = session.post(f\"{endpoint}?fields={fields}\", headers=headers, json=body_params)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Fetching comments for video {video_id} with cursor at {cursor}\")\n",
    "                \n",
    "            if response.status_code == 200:\n",
    "                data = response.json().get(\"data\", {})\n",
    "                comments = data.get(\"comments\", [])\n",
    "                \n",
    "                if comments:\n",
    "                    comments_df = pd.DataFrame(comments)\n",
    "                    comments_df['video_id'] = video_id  # Add the video_id to each comment\n",
    "                    all_comments_df = pd.concat([all_comments_df, comments_df], ignore_index=True)\n",
    "                \n",
    "                has_more = data.get(\"has_more\", False)\n",
    "                cursor += max_count  # Increment cursor based on max_count\n",
    "            elif response.status_code == 429:\n",
    "                if verbose:\n",
    "                    print(\"Rate limit exceeded. Pausing before retrying...\")\n",
    "                sleep(30)  # Pause execution before retrying\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"Error fetching comments for video {video_id}: {response.status_code}\", response.json())\n",
    "                break  # Stop the loop in case of an error\n",
    "\n",
    "    return all_comments_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
